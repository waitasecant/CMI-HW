{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Himanshu, MDS202327","metadata":{}},{"cell_type":"markdown","source":"#### Importing packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T10:09:39.489349Z","iopub.execute_input":"2025-04-17T10:09:39.489654Z","iopub.status.idle":"2025-04-17T10:09:39.493842Z","shell.execute_reply.started":"2025-04-17T10:09:39.489632Z","shell.execute_reply":"2025-04-17T10:09:39.493220Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"#### Preprocessing","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/train.csv\", encoding=\"latin1\")\ndf_test = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/test.csv\", encoding=\"latin1\")\n\n# Select necessary columns and remove the null values\ndf_train = pd.DataFrame(df_train[['text', 'sentiment']])\ndf_train = df_train.dropna()\n\ndf_test = pd.DataFrame(df_test[['text', 'sentiment']])\ndf_test = df_test.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.499828Z","iopub.execute_input":"2025-04-17T09:42:20.500382Z","iopub.status.idle":"2025-04-17T09:42:20.703832Z","shell.execute_reply.started":"2025-04-17T09:42:20.500360Z","shell.execute_reply":"2025-04-17T09:42:20.703210Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.705617Z","iopub.execute_input":"2025-04-17T09:42:20.705892Z","iopub.status.idle":"2025-04-17T09:42:20.711932Z","shell.execute_reply.started":"2025-04-17T09:42:20.705872Z","shell.execute_reply":"2025-04-17T09:42:20.711119Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((27480, 2), (3534, 2))"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.712955Z","iopub.execute_input":"2025-04-17T09:42:20.713403Z","iopub.status.idle":"2025-04-17T09:42:20.740208Z","shell.execute_reply.started":"2025-04-17T09:42:20.713383Z","shell.execute_reply":"2025-04-17T09:42:20.739528Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text sentiment\n0                I`d have responded, if I were going   neutral\n1      Sooo SAD I will miss you here in San Diego!!!  negative\n2                          my boss is bullying me...  negative\n3                     what interview! leave me alone  negative\n4   Sons of ****, why couldn`t they put them on t...  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df_train['sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.741182Z","iopub.execute_input":"2025-04-17T09:42:20.741484Z","iopub.status.idle":"2025-04-17T09:42:20.752218Z","shell.execute_reply.started":"2025-04-17T09:42:20.741459Z","shell.execute_reply":"2025-04-17T09:42:20.751647Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"sentiment\nneutral     11117\npositive     8582\nnegative     7781\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_test['sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.753097Z","iopub.execute_input":"2025-04-17T09:42:20.753327Z","iopub.status.idle":"2025-04-17T09:42:20.769993Z","shell.execute_reply.started":"2025-04-17T09:42:20.753309Z","shell.execute_reply":"2025-04-17T09:42:20.769198Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"sentiment\nneutral     1430\npositive    1103\nnegative    1001\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Mp the labels\nlabel_map = {'positive': 2, 'neutral': 1, 'negative': 0}\ndf_train['label'] = df_train['sentiment'].map(label_map)\ndf_test['label'] = df_test['sentiment'].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.770771Z","iopub.execute_input":"2025-04-17T09:42:20.771121Z","iopub.status.idle":"2025-04-17T09:42:20.790259Z","shell.execute_reply.started":"2025-04-17T09:42:20.771100Z","shell.execute_reply":"2025-04-17T09:42:20.789475Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#### Custom Data Set","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            return_token_type_ids=False,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].flatten(),\n            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n            \"labels\": torch.tensor(label, dtype=torch.long),\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.791071Z","iopub.execute_input":"2025-04-17T09:42:20.791324Z","iopub.status.idle":"2025-04-17T09:42:20.806601Z","shell.execute_reply.started":"2025-04-17T09:42:20.791299Z","shell.execute_reply":"2025-04-17T09:42:20.805921Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#### Model Building","metadata":{}},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:20.808942Z","iopub.execute_input":"2025-04-17T09:42:20.809209Z","iopub.status.idle":"2025-04-17T09:42:20.826824Z","shell.execute_reply.started":"2025-04-17T09:42:20.809192Z","shell.execute_reply":"2025-04-17T09:42:20.826171Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T10:09:46.934250Z","iopub.execute_input":"2025-04-17T10:09:46.934551Z","iopub.status.idle":"2025-04-17T10:09:47.552788Z","shell.execute_reply.started":"2025-04-17T10:09:46.934527Z","shell.execute_reply":"2025-04-17T10:09:47.552002Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_dataset = CustomDataset(df_train['text'].tolist(), df_train['label'].tolist(), tokenizer)\ntest_dataset = CustomDataset(df_test['text'].tolist(), df_test['label'].tolist(), tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:24.562763Z","iopub.execute_input":"2025-04-17T09:42:24.563070Z","iopub.status.idle":"2025-04-17T09:42:24.570140Z","shell.execute_reply.started":"2025-04-17T09:42:24.563044Z","shell.execute_reply":"2025-04-17T09:42:24.569462Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"epochs = 5\nlearning_rate = 2e-5\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:24.571065Z","iopub.execute_input":"2025-04-17T09:42:24.571340Z","iopub.status.idle":"2025-04-17T09:42:24.808570Z","shell.execute_reply.started":"2025-04-17T09:42:24.571317Z","shell.execute_reply":"2025-04-17T09:42:24.807563Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"#### Training model","metadata":{}},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    total_loss = 0.0\n    total_batches = 0\n    for batch_idx, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        total_batches += 1\n\n        # Print loss for batch (only the multiples of 100)\n        if batch_idx %100 == 99:\n          print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.6f}\")\n\n    avg_loss = total_loss / total_batches\n    print()\n    # Print average loss for each epoch\n    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_loss:.6f}\", end = \"\\n\")\n    print(50*'-')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:42:24.809488Z","iopub.execute_input":"2025-04-17T09:42:24.810027Z","iopub.status.idle":"2025-04-17T10:09:20.343033Z","shell.execute_reply.started":"2025-04-17T09:42:24.810001Z","shell.execute_reply":"2025-04-17T10:09:20.342147Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5, Batch 100/859, Loss: 0.598016\nEpoch 1/5, Batch 200/859, Loss: 0.565505\nEpoch 1/5, Batch 300/859, Loss: 0.685714\nEpoch 1/5, Batch 400/859, Loss: 0.507706\nEpoch 1/5, Batch 500/859, Loss: 0.838196\nEpoch 1/5, Batch 600/859, Loss: 0.508803\nEpoch 1/5, Batch 700/859, Loss: 0.436642\nEpoch 1/5, Batch 800/859, Loss: 0.521657\n\nEpoch 1/5, Average Training Loss: 0.584671\n--------------------------------------------------\nEpoch 2/5, Batch 100/859, Loss: 0.520245\nEpoch 2/5, Batch 200/859, Loss: 0.318612\nEpoch 2/5, Batch 300/859, Loss: 0.473606\nEpoch 2/5, Batch 400/859, Loss: 0.602207\nEpoch 2/5, Batch 500/859, Loss: 0.170384\nEpoch 2/5, Batch 600/859, Loss: 0.430223\nEpoch 2/5, Batch 700/859, Loss: 0.258519\nEpoch 2/5, Batch 800/859, Loss: 0.489507\n\nEpoch 2/5, Average Training Loss: 0.421391\n--------------------------------------------------\nEpoch 3/5, Batch 100/859, Loss: 0.153960\nEpoch 3/5, Batch 200/859, Loss: 0.277719\nEpoch 3/5, Batch 300/859, Loss: 0.677034\nEpoch 3/5, Batch 400/859, Loss: 0.338415\nEpoch 3/5, Batch 500/859, Loss: 0.423015\nEpoch 3/5, Batch 600/859, Loss: 0.320989\nEpoch 3/5, Batch 800/859, Loss: 0.271656\n\nEpoch 3/5, Average Training Loss: 0.300464\n--------------------------------------------------\nEpoch 4/5, Batch 100/859, Loss: 0.097795\nEpoch 4/5, Batch 200/859, Loss: 0.197033\nEpoch 4/5, Batch 300/859, Loss: 0.163963\nEpoch 4/5, Batch 400/859, Loss: 0.205752\nEpoch 4/5, Batch 500/859, Loss: 0.263213\nEpoch 4/5, Batch 600/859, Loss: 0.112281\nEpoch 4/5, Batch 700/859, Loss: 0.121088\nEpoch 4/5, Batch 800/859, Loss: 0.145327\n\nEpoch 4/5, Average Training Loss: 0.186707\n--------------------------------------------------\nEpoch 5/5, Batch 100/859, Loss: 0.294192\nEpoch 5/5, Batch 200/859, Loss: 0.024303\nEpoch 5/5, Batch 300/859, Loss: 0.042265\nEpoch 5/5, Batch 400/859, Loss: 0.096528\nEpoch 5/5, Batch 500/859, Loss: 0.050743\nEpoch 5/5, Batch 600/859, Loss: 0.064810\nEpoch 5/5, Batch 700/859, Loss: 0.333823\nEpoch 5/5, Batch 800/859, Loss: 0.055695\n\nEpoch 5/5, Average Training Loss: 0.122103\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model.eval()\ntrue_labels = []\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"]\n        true_labels.extend(labels.tolist())\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, predicted = torch.max(outputs.logits, 1)\n        predictions.extend(predicted.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T10:09:20.343981Z","iopub.execute_input":"2025-04-17T10:09:20.344447Z","iopub.status.idle":"2025-04-17T10:09:33.519456Z","shell.execute_reply.started":"2025-04-17T10:09:20.344403Z","shell.execute_reply":"2025-04-17T10:09:33.518185Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"#### Report","metadata":{}},{"cell_type":"code","source":"print(classification_report(true_labels, predictions, target_names=['negative', 'neutral', 'positive'], digits = 6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T10:09:33.520575Z","iopub.execute_input":"2025-04-17T10:09:33.520866Z","iopub.status.idle":"2025-04-17T10:09:33.539353Z","shell.execute_reply.started":"2025-04-17T10:09:33.520836Z","shell.execute_reply":"2025-04-17T10:09:33.538356Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative   0.749773  0.826174  0.786122      1001\n     neutral   0.769946  0.695105  0.730614      1430\n    positive   0.814912  0.842248  0.828355      1103\n\n    accuracy                       0.778155      3534\n   macro avg   0.778210  0.787842  0.781697      3534\nweighted avg   0.778267  0.778155  0.776842      3534\n\n","output_type":"stream"}],"execution_count":16}]}